{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Predicting Country Life Expectancy.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"zWehVuzaeT2d"},"source":["## **Columns/Features**\n","\n","**Country** Country\n","\n","**Year** Year\n","\n","**Status** Developed or Developing status\n","\n","**Life expectancy** Life Expectancy in age\n","\n","**Adult Mortality** Adult Mortality Rates of both sexes (probability of dying between 15 and 60 years per 1000 population)\n","\n","**infant** deaths Number of Infant Deaths per 1000 population\n","\n","**Alcohol** Alcohol, recorded per capita (15+) consumption (in litres of pure alcohol)\n","percentage \n","\n","**expenditure** Expenditure on health as a percentage of Gross Domestic Product per capita(%)\n","\n","**Hepatitis B** Hepatitis B (HepB) immunization coverage among 1-year-olds (%)\n","\n","**Measles** Measles - number of reported cases per 1000 population\n","\n","**BMI** Average Body Mass Index of entire population\n","\n","**under-five deaths** Number of under-five deaths per 1000 population\n","\n","**Polio** Polio (Pol3) immunization coverage among 1-year-olds (%)\n","\n","**Total expenditure** General government expenditure on health as a percentage of total government expenditure (%)\n","\n","**Diphtheria** Diphtheria tetanus toxoid and pertussis (DTP3) immunization coverage among 1-year-olds (%)\n","\n","**HIV/AIDS** Deaths per 1 000 live births HIV/AIDS (0-4 years)\n","\n","**GDP** Gross Domestic Product per capita (in USD)\n","\n","**Population** Population of the country\n","\n","**thinness 1-19 years** Prevalence of thinness among children and adolescents for Age 10 to 19 (% )\n","\n","**thinness 5-9 years** Prevalence of thinness among children for Age 5 to 9(%)\n","\n","**Income composition of resources** Human Development Index in terms of income composition of resources (index ranging from 0 to 1)\n","\n","**Schooling** Number of years of Schooling(years) "]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["\n","%%capture\n","!pip install eli5\n","!pip install pdpbox\n","!pip install shap\n","!pip install category_encoders==2.*\n","!pip install pandas-profiling==2.*"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[1;32m<ipython-input-2-a32025f46705>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Importing Libraries needed for the project.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpandas_profiling\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRidge\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37-32\\lib\\site-packages\\pandas_profiling\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas_profiling\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas_profiling\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontroller\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas_decorator\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas_profiling\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtemplates\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtemplates\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas_profiling\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdescribe\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdescribe\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mdescribe_df\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37-32\\lib\\site-packages\\pandas_profiling\\controller\\pandas_decorator.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;34m\"\"\"This file add the decorator on the DataFrame object.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas_profiling\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mProfileReport\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37-32\\lib\\site-packages\\pandas_profiling\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas_profiling\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontroller\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas_decorator\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas_profiling\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtemplates\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtemplates\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas_profiling\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdescribe\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdescribe\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mdescribe_df\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas_profiling\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnotebook\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdisplay_notebook_iframe\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas_profiling\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreport\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mto_html\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37-32\\lib\\site-packages\\pandas_profiling\\model\\describe.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas_profiling\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbase\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas_profiling\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m from pandas_profiling.model.correlations import (\n\u001b[0m\u001b[0;32m     25\u001b[0m     \u001b[0mcalculate_correlations\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[0mperform_check_correlation\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37-32\\lib\\site-packages\\pandas_profiling\\model\\correlations.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mconfuse\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mNotFoundError\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDataError\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mstats\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas_profiling\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37-32\\lib\\site-packages\\scipy\\stats\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    379\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mstats\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    380\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mdistributions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 381\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mmorestats\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    382\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_binned_statistic\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mkde\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgaussian_kde\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37-32\\lib\\site-packages\\scipy\\stats\\morestats.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mstats\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mstats\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfind_repeats\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_contains_nan\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mcontingency\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mchi2_contingency\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdistributions\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_distn_infrastructure\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrv_generic\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37-32\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n","\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37-32\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n","\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37-32\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n","\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37-32\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n","\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37-32\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36mget_code\u001b[1;34m(self, fullname)\u001b[0m\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# Importing Libraries needed for the project. \n","import pandas_profiling\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LinearRegression, Ridge\n","from sklearn.metrics import mean_absolute_error, r2_score\n","import category_encoders as ce\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.pipeline import make_pipeline\n","from sklearn.tree import DecisionTreeRegressor\n","import matplotlib.pyplot as plt\n","from sklearn.ensemble import RandomForestRegressor\n","from xgboost import XGBRegressor\n","import eli5\n","from eli5.sklearn import PermutationImportance\n","%matplotlib inline\n","plt.rcParams['figure.dpi'] = 72\n","from pdpbox.pdp import pdp_isolate, pdp_plot\n","from pdpbox.pdp import pdp_interact, pdp_interact_plot\n","import seaborn as sns\n","import plotly.graph_objects as go\n","import shap;"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"nz1L0P_rfkrW"},"source":["## **Data Leakage Features and Why**\n","\n","**Income composition of resources** - The Human Development Index (HDI) is a statistic composite index of life expectancy, education, and per capita income indicators, which are used to rank countries into four tiers of human development. A country scores a higher HDI when the lifespan is higher, the education level is higher, and the gross national income GNI (PPP) per capita is higher. https://en.wikipedia.org/wiki/Human_Development_Index\n","\n","\n","**expenditure** is using GDP and total expenditure\n","\n","**infant mortality** could also be representated by under_five_deaths\n","\n","**under_five_deaths and adult mortality** Adult mortality is “The number of people that die between ages 15 and 60 yrs old per 1000 people” If this feature is in the predictive model, then the insight would be “In countries where more people die young, people don’t live as long on average.”"]},{"cell_type":"code","execution_count":0,"metadata":{},"outputs":[],"source":["# Loading the data\n","data = 'https://raw.githubusercontent.com/EvidenceN/Life-Expectancy-Prediction/master/Life%20Expectancy/Data/Life%20Expectancy%20Data.csv'\n","\n","life = pd.read_csv(data)\n","\n","print(life.shape)\n","life.head()"]},{"cell_type":"code","execution_count":0,"metadata":{},"outputs":[],"source":["# Get a profile report of the dataset. \n","profile = pandas_profiling.ProfileReport(life)\n","profile"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"1KbMEjKwwfNO"},"source":["**Dealing with missing data.** A lot of GDP and Population data is missing for some countries. \n","\n","Due to the nature of the dataset, i can not use imputation with a mean or median strategy. If i use imputation, then i am taking information from other countries and putting it in for a different country. \n","\n","for example, i will be taking population and GDP information from a different countries and imputing it as the population and GDP of a different countries. That information would be inaccurate. \n","\n","I could meticoulously look up the information from the countries with missing data, but that would consume a lot of time. \n","\n","Drop rows with missing gdp and population information. That would leave me with 145 countries instead of 193 and \n","75% of the total data. By doing this, i will loose 25% of the data. \n","\n","for other features like Bmi, thinness, hepatitis B with missing values, i will input 0's for those missing values. \n","if values are missing for those features, 0 is a safe assumption and won't skew the data or disrupt the interpretation\n","of the data\n","\n","XGboost can handle nan, but other models might struggle to handle nan, since imputation is not a viable option, then\n","i will use 0 in place of nan's\n","\n","drop country and years because we are not trying to see if the life exptancy of a country changes from year to year. The country and year the data originated from should \n","not be a predictor of life expectancy. \n","\n","The objective is to use health and economic factors to predict life expectancy. Having data from different countries over the\n","years allows for diversity of information. "]},{"cell_type":"code","execution_count":0,"metadata":{},"outputs":[],"source":["# drop gdp and population and life expectancy missing values\n","life = life.dropna(subset=['GDP', 'Population', 'Life_expectancy_'])"]},{"cell_type":"code","execution_count":0,"metadata":{},"outputs":[],"source":["# get the mean baseline because this is a regression problem\n","# with regression, the baseline can be as simple as the mean.\n","\n","mean_baseline = life['Life_expectancy_'].mean()\n","errors = mean_baseline - life['Life_expectancy_']\n","mean_absolute_error_ = errors.abs().mean()\n","print(f'Mean Baseline: {mean_baseline:.1f} years')\n","print('Without any other factors, life expectancy could be guessed to be')\n","print(f'{mean_baseline:.1f}yrs and will be off by a mean absolute error of {round(mean_absolute_error_, 2)}')"]},{"cell_type":"code","execution_count":0,"metadata":{},"outputs":[],"source":["# split into train, test, validation 15% for testing, 15% for validation, 70% training. \n","# No stratification in splitting because of ValueError: The least populated class in y has \n","# only 1 member, which is too few. The minimum number of groups for any class cannot be less than 2.\n","\n","from sklearn.model_selection import train_test_split\n","\n","train, test = train_test_split(life, test_size=0.15, random_state=42)\n","\n","train, val = train_test_split(train, test_size=0.20, random_state=42)"]},{"cell_type":"code","execution_count":0,"metadata":{},"outputs":[],"source":["# function to perform data cleaning on all datasets. \n","\n","def wrangle(x):\n","    x = x.copy()\n","    \n","    x.columns = [col.lower()         # make column names lowercase\n","                .strip('_')         # strip leading/trailing underscores\n","                .replace('_', ' ')  # replace remaining punctuation with spaces\n","                .replace('-', ' ') \n","                .replace('/', ' ')\n","                for col in x.columns]\n","    \n","    # dropping columns with leakage\n","    x = x.drop(columns = ['country', 'year', 'income composition of resources',\n","                         'percentage expenditure', 'infant deaths', \n","                          'under five deaths', 'adult mortality'])\n","    \n","    # filling nan values with 0 because I can't do imputation and the missing\n","    # values can be assumed to be 0.\n","    \n","    x = x.fillna(value=0)\n","    \n","    return x"]},{"cell_type":"code","execution_count":0,"metadata":{},"outputs":[],"source":["# clean all data the same way\n","train = wrangle(train)\n","test = wrangle(test)\n","val = wrangle(val)"]},{"cell_type":"code","execution_count":0,"metadata":{},"outputs":[],"source":["# defining x and y values for training, validation, and test sets. \n","\n","target = 'life expectancy'\n","features = train.columns.drop(target)\n","\n","x_train = train[features]\n","y_train = train[target]\n","x_val = val[features]\n","y_val = val[target]\n","x_test = test[features]\n","y_test = test[target]"]},{"cell_type":"code","execution_count":0,"metadata":{},"outputs":[],"source":["# Function to build multiple Models at once. \n","\n","def model(x_train, y_train, x_val, y_val):\n","\n","  # Defining Global Coefficients so that it can be used\n","  # outside of the function. \n","  global coefficients_lr, coefficients_ridge, importances_tree\n","  global importances_boost, importances_forest, forest\n","\n","  ##lr = linear regression model\n","  \n","  lr = make_pipeline(\n","      ce.OneHotEncoder(),\n","      LinearRegression())\n","  \n","  # Getting error and R^2 scores from linear regression model. \n","  # fitting the model from linear regression pipeline\n","  lr.fit(x_train, y_train)\n","  # R2 score from linear regression model\n","  lr_score = lr.score(x_val, y_val)\n","  print(f'LinearRegression R^2 Score {lr_score}')\n","  # mean absolute error from linear regression model\n","  y_pred_lr = lr.predict(x_val)\n","  mae_lr = mean_absolute_error(y_val, y_pred_lr)\n","  print(f'LinearRegression mean_absolute_error {mae_lr}\\n' )\n","  # coefficients from linear regression model\n","  coeff_lr = lr.named_steps['linearregression'].coef_\n","  print(f'LinearRegression Coefficient {coeff_lr}')\n","  #Intercept from linear regression model. \n","  intercept_lr = lr.named_steps['linearregression'].intercept_\n","  print(f'LinearRegression Intercept {intercept_lr}\\n')\n","\n","  # plotting the coefficients from linear regression model.\n","  encoder = lr.named_steps['onehotencoder']\n","  columns_lr = encoder.transform(x_val).columns\n","  coefficients_lr = pd.Series(coeff_lr, columns_lr)\n","\n","  ## Ridge Regression Model\n","\n","  ridge = make_pipeline(\n","        ce.OneHotEncoder(),\n","        StandardScaler(),\n","        Ridge(alpha=10))\n","\n","  # fitting the model\n","  ridge.fit(x_train, y_train)\n","\n","  # mean absolute error for ridge regresssion model\n","  y_pred_ridge = ridge.predict(x_val)\n","  mae_ridge = mean_absolute_error(y_val, y_pred_ridge)\n","  print(f'Ridge regression mean_absolute_error {mae_ridge}' )\n","\n","  # R2 score for ridge regresssion model\n","  ridge_score = ridge.score(x_val, y_val,)\n","  print(f'Ridge Regression Score R^2 Score {ridge_score}\\n')\n","\n","  coeff_ridge = ridge.named_steps['ridge'].coef_\n","  print(f'Ridge Regression Coefficient {coeff_ridge}')\n","\n","  intercept_ridge = ridge.named_steps['ridge'].intercept_\n","  print(f'Ridge Regression Intercept {intercept_ridge}\\n')\n","\n","  # plotting the coefficients for ridge regresssion model\n","  encoder = ridge.named_steps['onehotencoder']\n","  columns_ridge = encoder.transform(x_val).columns\n","  coefficients_ridge = pd.Series(coeff_ridge, columns_ridge)\n","\n","  ## Decision Tree Model\n","\n","  tree = make_pipeline(\n","    ce.OrdinalEncoder(),\n","    DecisionTreeRegressor(random_state=42))\n","\n","  tree.fit(x_train, y_train)\n","\n","  # mean absolute error for decision tree model\n","  y_pred = tree.predict(x_val)\n","  mae = mean_absolute_error(y_val, y_pred)\n","  print(f'Decision tree mean_absolute_error {mae}' )\n","\n","  # R2 score for decision tree model\n","  tree_score = tree.score(x_val, y_val,)\n","  print(f'Decision tree Score R^2 Score {tree_score}\\n')\n","\n","  # plotting the feature importances for decision tree model\n","  tree_model = tree.named_steps['decisiontreeregressor']\n","  encoder = tree.named_steps['ordinalencoder']\n","  columns = encoder.transform(x_val).columns\n","  importances_tree = pd.Series(tree_model.feature_importances_, columns)\n","\n","  ## random forest model\n","\n","  forest = make_pipeline(\n","      ce.OrdinalEncoder(),\n","      RandomForestRegressor(random_state=42, n_estimators=100, n_jobs=-1)\n","  )\n","\n","  forest.fit(x_train, y_train)\n","\n","  # mean absolute error for random forest model\n","  y_pred_val = forest.predict(x_val)\n","  mae = mean_absolute_error(y_val, y_pred_val)\n","  print(f'random forest mean_absolute_error {mae}' )\n","\n","  # R2 score for random forest model\n","  forest_score = forest.score(x_val, y_val,)\n","\n","  print(f'random forest Score R^2 Score {forest_score}\\n')\n","\n","  # plotting the feature importances for random forest model\n","  model_forest = forest.named_steps['randomforestregressor']\n","  encoder = forest.named_steps['ordinalencoder']\n","  columns = encoder.transform(x_val).columns\n","  importances_forest = pd.Series(model_forest.feature_importances_, columns)\n","\n","  ## gradient boosting model\n","\n","  boost = make_pipeline(\n","      ce.OrdinalEncoder(),\n","      XGBRegressor(random_state=42, n_estimators=100, n_jobs=-1)\n","  );\n","\n","  boost.fit(x_train, y_train)\n","\n","  # mean absolute error for gradient boosting model\n","  y_pred_boost = boost.predict(x_val)\n","  mae_boost = mean_absolute_error(y_val, y_pred_boost)\n","  print(f'gradient boosting mean_absolute_error {mae_boost}' )\n","\n","  # R2 score for gradient boosting model\n","  boost_score = boost.score(x_val, y_val,)\n","  print(f'gradient boosting R^2 Score {boost_score}')\n","\n","  # defining the dataframe for plotting the feature importances for gradient boosting model\n","  model_boost = boost.named_steps['xgbregressor']\n","  encoder = boost.named_steps['ordinalencoder']\n","  columns = encoder.transform(x_val).columns\n","  importances_boost = pd.Series(model_boost.feature_importances_, columns);"]},{"cell_type":"code","execution_count":0,"metadata":{},"outputs":[],"source":["model(x_train, y_train, x_val, y_val)"]},{"cell_type":"code","execution_count":0,"metadata":{},"outputs":[],"source":["# Visualization for Linear Regression model.\n","coefficients_lr.sort_values().plot.barh(color='grey')\n","plt.title('Visualization for Linear Regression Model Coefficients')"]},{"cell_type":"code","execution_count":0,"metadata":{},"outputs":[],"source":["# Visualization for Ridge Regression model.\n","coefficients_ridge.sort_values().plot.barh(color='grey')\n","plt.title('Visualization for Ridge Regression Model Coefficients')"]},{"cell_type":"code","execution_count":0,"metadata":{},"outputs":[],"source":["# Visualization for Decision model.\n","importances_tree.sort_values().plot.barh(color='grey')\n","plt.title('Visualization for Decision Tree Model Feature Importances')"]},{"cell_type":"code","execution_count":0,"metadata":{},"outputs":[],"source":["# Visualization for Random Forest model.\n","importances_forest.sort_values().plot.barh(color='grey')\n","plt.title('Visualization for Random Forest Model Feature Importances')"]},{"cell_type":"code","execution_count":0,"metadata":{},"outputs":[],"source":["# Visualization for gradient boost model.\n","importances_boost.sort_values().plot.barh(color='grey')\n","plt.title('Visualization for Gradient Boosting Model Feature Importances')"]},{"cell_type":"code","execution_count":0,"metadata":{},"outputs":[],"source":["# using the best model which is the random forest model for prediction\n","# with the test data set. \n","y_pred_test = forest.predict(x_test)\n","mae = mean_absolute_error(y_test, y_pred_test)\n","print(f'random forest test mean_absolute_error {mae}' )\n","\n","# R2 score for test data set\n","forest_score = forest.score(x_test, y_test,)\n","print(f'random forest test Score R^2 Score {forest_score}')"]},{"cell_type":"code","execution_count":0,"metadata":{},"outputs":[],"source":["# Permutation Importance Function. Eli5 - the library used for permutation\n","# importance calculations doesn't work with pipeline models. So, everything has\n","# to be preprocess before putting it in a model. \n","\n","def permutation(x_train, y_train, x_val, y_val):\n","\n","  # Pre processing the data using a pipeline\n","  pre_processing = make_pipeline(\n","      ce.OrdinalEncoder())\n","\n","  x_train_encoded =  pre_processing.fit_transform(x_train)\n","  x_val_encoded =  pre_processing.transform(x_val)\n","\n","  # fitting the model\n","  model = RandomForestRegressor(n_estimators=100, n_jobs=-1, random_state=42)\n","  model.fit(x_train_encoded, y_train)\n","\n","  # instantiating and setting the permutation parameters\n","  permuter = PermutationImportance(\n","      model,\n","      scoring = 'r2', \n","      n_iter = 5,\n","      random_state = 42\n","  )\n","\n","  # fitting the permutation importance to the validation dataset\n","  permuter.fit(x_val_encoded, y_val)\n","\n","  # getting and plotting the graph from the permution calculations\n","  feature_names = x_val.columns.to_list()\n","  pd.Series(permuter.feature_importances_, feature_names).sort_values(ascending=False)\n","\n","  metric = eli5.show_weights(\n","      permuter,\n","      top=None,\n","      feature_names=feature_names,\n","  )\n","\n","  return metric"]},{"cell_type":"code","execution_count":0,"metadata":{},"outputs":[],"source":["permutation(x_train, y_train, x_val, y_val)"]},{"cell_type":"code","execution_count":0,"metadata":{},"outputs":[],"source":["# Function for single feature partial dependence plot(PDP)\n","\n","def pdp(feature, title=\"\", ylabel=\"\", xlabel=\"\", xlim=(0,10)):\n","\n","  # defining the parameters for the pdp plot\n","  isolated = pdp_isolate(\n","    model=forest,\n","    dataset=x_val,\n","    model_features = x_val.columns,\n","    feature = feature,\n","    num_grid_points=50\n","    )\n","\n","  # plotting the isolated features\n","  pdp_plot(isolated, feature_name=feature)\n","  plt.xlim(xlim)\n","  plt.title(title)\n","  plt.ylabel(ylabel)\n","  plt.xlabel(xlabel)"]},{"cell_type":"code","execution_count":0,"metadata":{},"outputs":[],"source":["# pdp plot for HIV AIDS feature\n","pdp('hiv aids', \n","    title = \"Partial Dependence of life expectancy on 'HIV AIDS'\",\n","    ylabel='Life Expectancy',\n","    xlabel='Death by HIV Aids in 0-4yr old per 1000 people')"]},{"cell_type":"code","execution_count":0,"metadata":{},"outputs":[],"source":["# pdp plot for schooling feature\n","pdp('schooling', \n","    title=\"Partial Dependence of life expectancy on 'Number of years in school'\",\n","    ylabel='Life Expectancy',\n","    xlabel = 'Number of years in school',\n","    xlim=(None))"]},{"cell_type":"code","execution_count":0,"metadata":{},"outputs":[],"source":["# pdp plot for schooling feature\n","pdp('bmi', \n","    title=\"Partial Dependence of life expectancy on 'Body Mass Index'\",\n","    ylabel='Life Expectancy',\n","    xlabel = 'Average Body Mass Index of entire population',\n","    xlim=(None))"]},{"cell_type":"code","execution_count":0,"metadata":{},"outputs":[],"source":["#2d PDP Plot function\n","\n","def pdp_2d(feature1, feature2, x_val, model, title=''):\n","\n","  #Defining the parameters for the pdp interaction\n","\n","  features=[feature1, feature2]\n","\n","  interaction = pdp_interact(\n","    model=model,\n","    dataset=x_val,\n","    model_features = x_val.columns,\n","    features=features)\n","  \n","  # putting the pdp in a table format and plotting it\n","\n","  # 2 options. \n","\n","  # option 1: This will just plot the pdp interaction\n","\n","  #pdp_interact_plot(interaction, \n","                    #plot_type='grid', feature_names=features)\n","\n","  # Option 2: Taking the pdp interaction and plotting it using\n","  # a seaborn heatmap. \n","\n","  pdp = interaction.pdp.pivot_table(\n","    values='preds',\n","    columns=features[0],\n","    index=features[1])[::-1]\n","\n","  plt.figure(figsize=(10,8))\n","  sns.heatmap(pdp, annot=True, fmt='.2f', cmap='viridis', xticklabels=pdp.columns.values.round(2),\n","                 yticklabels=pdp.index.values.round(2))\n","  plt.title(title);"]},{"cell_type":"code","execution_count":0,"metadata":{},"outputs":[],"source":["# 2d pdp plot of HIV Aids and Schooling\n","\n","pdp_2d('hiv aids', 'schooling', x_val, forest,\n","       title='Partial dependence of life expectancy on HIV AIDS death rate per 1000 people and number of years in school')\n"]},{"cell_type":"code","execution_count":0,"metadata":{},"outputs":[],"source":["pdp_2d('hiv aids', 'bmi', x_val, forest,\n","       title='Partial dependence of life expectancy on HIV AIDS death rate per 1000 people and Body Mass Index')"]},{"cell_type":"code","execution_count":0,"metadata":{},"outputs":[],"source":["pdp_2d('schooling', 'bmi', x_val, forest,\n","       title='Partial dependence of life expectancy on number of years in school and Body Mass Index')"]},{"cell_type":"code","execution_count":0,"metadata":{},"outputs":[],"source":["# 3d partial independence plots function\n","\n","def pdp_3d(feature1, feature2, x_val, model, target, title=''):\n","\n","  #Defining the parameters for the pdp interaction\n","\n","  features=[feature1, feature2]\n","\n","  interaction = pdp_interact(\n","    model=model,\n","    dataset=x_val,\n","    model_features = x_val.columns,\n","    features=features)\n","  \n","  # putting the pdp in a table format and plotting it\n","\n","  pdp = interaction.pdp.pivot_table(\n","    values='preds',\n","    columns=features[0],\n","    index=features[1])[::-1]\n","\n","  # defining the graph area for the 3d plot\n","\n","  surface = go.Surface(\n","      x=pdp.columns,\n","      y=pdp.index,\n","      z=pdp.values\n","  )\n","\n","  # defining the layout of the 3d graph. \n","  layout = go.Layout(\n","      scene=dict(\n","          xaxis=dict(title=features[0]), \n","          yaxis=dict(title=features[1]), \n","          zaxis=dict(title=target),),\n","          title=(title))\n","\n","  #Plotting the 3d graph\n","  \n","  fig = go.Figure(surface, layout)\n","  fig.show()\n"]},{"cell_type":"code","execution_count":0,"metadata":{},"outputs":[],"source":["pdp_3d('hiv aids', 'schooling', x_val, forest, 'life expectancy',\n","       title='Partial dependence of life expectancy on HIV AIDS death rate per 1000 people and number of years in school')"]},{"cell_type":"code","execution_count":0,"metadata":{},"outputs":[],"source":["pdp_3d('hiv aids', 'bmi', x_val, forest, 'life expectancy', \n","       title='Partial dependence of life expectancy on HIV AIDS death rate per 1000 people and Body Mass Index')"]},{"cell_type":"code","execution_count":0,"metadata":{},"outputs":[],"source":["pdp_3d('schooling', 'bmi', x_val, forest, 'life expectancy', \n","       title='Partial dependence of life expectancy on number of years in school and Body Mass Index')"]},{"cell_type":"code","execution_count":0,"metadata":{},"outputs":[],"source":["# function to do shapley plots. \n","\n","def shapley(x_train, y_train, x_val, row_number=0):\n","\n","  # encoding the x features from training and validation dataset. \n","\n","  encoding = ce.OrdinalEncoder()\n","\n","  x_train_encoded = encoding.fit_transform(x_train)\n","  x_val_encoded = encoding.transform(x_val)\n","\n","  model = RandomForestRegressor(n_estimators=100, n_jobs=-1, random_state=42)\n","  model.fit(x_train_encoded, y_train)\n","\n","  # defining what row to examine in the shapley plot\n","  row = x_val_encoded.iloc[[row_number]]\n","  \n","  # predicting\n","  pred = model.predict(row)\n","\n","  explainer = shap.TreeExplainer(model)\n","  shap_values = explainer.shap_values(row)\n","\n","  feature_names = row.columns\n","  feature_values = row.values[0]\n","  shaps = pd.Series(shap_values[0], zip(feature_names, feature_values))\n","  \n","  # printing the result\n","\n","  result = f'{pred[0]:.1f}yrs is the predicted life expectancy. \\n\\n'\n","  result += f'Starting from baseline of {explainer.expected_value:.1f}yrs \\n\\n'\n","  result += shaps.to_string()\n","  print(result)\n","\n","  shap.initjs()\n","\n","  return shap.force_plot(\n","      base_value = explainer.expected_value,\n","      shap_values = shap_values,\n","      features=row)\n","\n"]},{"cell_type":"code","execution_count":0,"metadata":{},"outputs":[],"source":["shapley(x_train, y_train, x_val)"]},{"cell_type":"code","execution_count":0,"metadata":{},"outputs":[],"source":["shapley(x_train, y_train, x_val, 13)"]},{"cell_type":"code","execution_count":0,"metadata":{},"outputs":[],"source":["shapley(x_train, y_train, x_val, 1)"]},{"cell_type":"code","execution_count":0,"metadata":{},"outputs":[],"source":["shapley(x_train, y_train, x_val, 37)"]},{"cell_type":"code","execution_count":0,"metadata":{},"outputs":[],"source":["import plotly.express as px\n","\n","px.scatter(train, x='hiv aids', y='life expectancy', \n","           title='Relationship between hiv aids and life expectancy')"]},{"cell_type":"code","execution_count":0,"metadata":{},"outputs":[],"source":["px.scatter(train, x='schooling', y='life expectancy', \n","           title='Relationship between schooling and life expectancy')"]},{"cell_type":"code","execution_count":0,"metadata":{},"outputs":[],"source":["px.scatter(train, x='bmi', y='life expectancy', \n","           title='Relationship between bmi and life expectancy')"]},{"cell_type":"code","execution_count":0,"metadata":{},"outputs":[],"source":["px.scatter_3d(test, x='hiv aids', y='life expectancy', z='schooling',\n","           title='Relationship between hiv aids, schooling, and life expectancy')"]},{"cell_type":"code","execution_count":0,"metadata":{},"outputs":[],"source":["px.scatter_3d(test, x='hiv aids', y='life expectancy', z='bmi',\n","           title='Relationship between hiv aids, BMI, and life expectancy')"]},{"cell_type":"code","execution_count":0,"metadata":{},"outputs":[],"source":["px.scatter_3d(test, x='schooling', y='life expectancy', z='bmi',\n","           title='Relationship between BMI, schooling, and life expectancy')"]},{"cell_type":"code","execution_count":0,"metadata":{},"outputs":[],"source":["# Feature Engineering\n","\n","life.head()"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"iWUNpwhksoGQ"},"source":["Immunization Feature:\n","Engineer a new feature that looks combines child hood/infancy immunization statististics. \n","\n","From the current dataset, infancy immunization rate features are\n","\n","Hepatitis B, Polio, Diphtheria. \n","\n","These features represent the percent of people that got immunization for those diseases between the ages of 0-1 yrs old. \n","\n","The new feature will combine all three immunization data to create a feature that tells how many infants got any form of the three immunizations. \n","\n","Hepatitis B, Polio, Diphtheria are in percentages. So the new feature will be calculated like this:\n","\n","Get the z score of Hepatitis B, Polio, Diphtheria, then take the average of all three scores as my new feature. "]},{"cell_type":"code","execution_count":0,"metadata":{},"outputs":[],"source":["# function to calculate z score for all three immunization \n","# features and compute the average z score. \n","\n","def z_score(x):\n","  x = x.copy()\n","\n","  # calculate the z scores for the features of interest\n","  x['polio_z_score'] = (x['polio']-x['polio'].mean())/x['polio'].std()\n","\n","  x['hepatitis_z_score'] = (x['hepatitis b']-x['hepatitis b'].mean())/x['hepatitis b'].std()\n","\n","  x['diphtheria_z_score'] = (x['diphtheria']-x['diphtheria'].mean())/x['diphtheria'].std()\n","\n","  # create a new feature that is the average of the z scores from all immunization features\n","  x['immunization'] = (x['polio_z_score'] + x['hepatitis_z_score'] \n","                       + x['diphtheria_z_score'])/3\n","\n","  # now drop the columns containing the original immunization features and the \n","  # columns that has the individual z scores since there is a new single \n","  # column(immunization) containing information from all 3 columns\n","\n","  return x"]},{"cell_type":"code","execution_count":0,"metadata":{},"outputs":[],"source":["# create a copy of the x_train, val, and test data sets above to avoid overiding them. \n","x_train_new = x_train\n","x_val_new = x_val\n","x_test_new = x_test"]},{"cell_type":"code","execution_count":0,"metadata":{},"outputs":[],"source":["x_train.head()"]},{"cell_type":"code","execution_count":0,"metadata":{},"outputs":[],"source":["# apply feature engineering function to the new x test sets.\n","x_train_new = z_score(x_train_new)\n","x_val_new = z_score(x_val_new)\n","x_test_new = z_score(x_test_new)"]},{"cell_type":"code","execution_count":0,"metadata":{},"outputs":[],"source":["# building the model using the new features. \n","\n","model(x_train_new, y_train, x_val_new, y_val)"]},{"cell_type":"code","execution_count":0,"metadata":{},"outputs":[],"source":["# linear regression visualization for the new model. \n","coefficients_lr.sort_values().plot.barh(color='grey')"]},{"cell_type":"code","execution_count":0,"metadata":{},"outputs":[],"source":["# Random Forest visualization for the new model. \n","importances_forest.sort_values().plot.barh(color='grey')"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"hUoctpU6G-Ny"},"source":["The new features doesn't make any difference in the model, So no further analysis will be done with it. "]}]}